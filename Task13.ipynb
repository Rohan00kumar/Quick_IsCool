{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Named Entity Recognition (NER) for Protein-Protein Interactions (PPI) in Biomedical Text Mining\n",
    "\n",
    "### Classical Computing Approach:\n",
    "\n",
    "1. Select a corpus of biomedical literature related to protein-protein interactions.\n",
    "\n",
    "2. Preprocess the corpus by:\n",
    "   - Removing stop words\n",
    "   - Removing punctuations\n",
    "   - Applying stemming or lemmatization\n",
    "\n",
    "3. Extract features from the preprocessed text, such as:\n",
    "   - Word shape\n",
    "   - Context\n",
    "   - Part-of-speech (POS) tags\n",
    "   - Chunking\n",
    "\n",
    "4. Train a machine learning model, such as:\n",
    "   - Conditional Random Fields (CRF)\n",
    "   - Support Vector Machines (SVM)\n",
    "   - Hidden Markov Models (HMM)\n",
    "\n",
    "5. Evaluation:\n",
    "   - Evaluate the model's performance using metrics such as precision, recall, and F1-score.\n",
    "\n",
    "### Quantum Computing Approach:\n",
    "\n",
    "1. Use quantum algorithms, such as Quantum Kernel Estimation (QKE) or Quantum Machine Learning (QML), to extract features from the preprocessed text.\n",
    "\n",
    "2. Train a quantum machine learning model, such as:\n",
    "   - Quantum Support Vector Machine (QSVM)\n",
    "   - Quantum Neural Network (QNN)\n",
    "\n",
    "3. Evaluation:\n",
    "   - Evaluate the model's performance using metrics such as precision, recall, and F1-score.\n",
    "\n",
    "4. Compare the efficiency of classical and quantum computing approaches.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"Protein A interacts with Protein B to activate pathway X.\",\n",
    "    \"Inhibition of Protein C prevents interaction with Protein D.\",\n",
    "    \"Protein E is a key regulator of pathway Y.\",\n",
    "    \"Protein F is a downstream target of pathway Z.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [1, 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "def preprocess(text):\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # Lowercase\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    # Remove punctuation\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    stripped = [w.translate(table) for w in tokens]\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in stripped if not w in stop_words]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preprocessing\n",
    "stop_words = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    filtered_tokens = [ps.stem(token) for token in tokens if token.isalnum() and token not in stop_words]\n",
    "    return \" \".join(filtered_tokens)\n",
    "\n",
    "preprocessed_corpus = [preprocess_text(doc) for doc in corpus]\n",
    "\n",
    "# Feature extraction\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(preprocessed_corpus)\n",
    "\n",
    "# Labels\n",
    "y = ['PPI' for _ in range(len(corpus))]  # Assuming all examples are protein-protein interactions\n",
    "\n",
    "# Split data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Support Vector Machine (SVM) model\n",
    "svm_classifier = LinearSVC()\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = svm_classifier.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Support Vector Machine (SVM) model\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluation\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# evaluatio of the model\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantum computing libraries are not yet mature for NLP tasks, so this is a conceptual example\n",
    "import qiskit_aer\n",
    "from qiskit import QuantumCircuit, Aer, transpile, assemble\n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "from qiskit.aqua import QuantumInstance\n",
    "from qiskit.aqua.algorithms import QSVM\n",
    "from qiskit import execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing (Not shown here as it's assumed to be done classically before quantum feature extraction)\n",
    "def quantum_text_classification(document):\n",
    "    # Quantum feature extraction\n",
    "    feature_map = ZZFeatureMap(feature_dimension=2, reps=2)\n",
    "    quantum_instance = QuantumInstance(backend=Aer.get_backend('qasm_simulator'), shots=1024)\n",
    "    qsvm = QSVM(feature_map, training_input, test_input, quantum_instance=quantum_instance)\n",
    "    result = qsvm.run()\n",
    "    return result[\"test_accuracy\"]\n",
    "\n",
    "# Labels\n",
    "labels = ['PPI' for _ in range(len(corpus))]  # Assuming all examples are protein-protein interactions\n",
    "# Text classification on the sample corpus\n",
    "accuracies = [quantum_text_classification(doc) for doc in corpus]\n",
    "print(accuracies)\n",
    "\n",
    "# Quantum feature extraction\n",
    "def quantum_feature_extraction(text):\n",
    "    \n",
    "    # Encode text as quantum state\n",
    "    qc = QuantumCircuit(2)\n",
    "    qc.h(0)\n",
    "    qc.cx(0, 1)\n",
    "    qc.barrier()\n",
    "    \n",
    "    # Measure quantum state\n",
    "    qc.measure_all()\n",
    "    \n",
    "    # Simulate quantum circuit\n",
    "    simulator = Aer.get_backend('qasm_simulator')\n",
    "    result = execute(qc, simulator, shots=1000).result()\n",
    "    counts = result.get_counts(qc)\n",
    "    \n",
    "    # Extract features from measurement outcomes\n",
    "    features = [0, 0]\n",
    "    for key, value in counts.items():\n",
    "        if key == '00':\n",
    "            features[0] = value\n",
    "        elif key == '11':\n",
    "            features[1] = value\n",
    "    \n",
    "    return features / np.sum(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantum machine learning model training\n",
    "def quantum_model_training(features, labels):\n",
    "        \n",
    "        # Encode labels as quantum states\n",
    "        qc = QuantumCircuit(1)\n",
    "        if labels[0] == 1:\n",
    "            qc.x(0)\n",
    "        qc.h(0)\n",
    "        qc.barrier()\n",
    "        \n",
    "        # Measure quantum state\n",
    "        qc.measure_all()\n",
    "        \n",
    "        # Simulate quantum circuit\n",
    "        simulator = Aer.get_backend('qasm_simulator')\n",
    "        result = execute(qc, simulator, shots=1000).result()\n",
    "        counts = result.get_counts(qc)\n",
    "        \n",
    "        # Extract parameters from measurement outcomes\n",
    "        parameter = 0\n",
    "        for key, value in counts.items():\n",
    "            if key == '1':\n",
    "                parameter = value\n",
    "        \n",
    "        return parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the function with random data\n",
    "features = [quantum_feature_extraction(doc) for doc in corpus]\n",
    "labels = [random.randint(0, 1) for _ in range(len(corpus))]\n",
    "\n",
    "print(\"Features shape:\", np.array(features).shape)\n",
    "print(\"Labels shape:\", np.array(labels).shape)\n",
    "\n",
    "# Training a quantum classifier on the features and labels\n",
    "classifier = quantum_model_training(features, labels)\n",
    "\n",
    "# Quantum evaluation\n",
    "def quantum_evaluation(model, test_features, test_labels):\n",
    "    \n",
    "    # Encode test features as quantum states\n",
    "    test_states = [quantum_feature_extraction(doc) for doc in test_features]\n",
    "    \n",
    "    # Evaluate the quantum model\n",
    "    predictions = [model.predict(state) for state in test_states]\n",
    "    \n",
    "    # Evaluate the predictions\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Quantum evaluation\n",
    "test_features = [\"Protein A interacts with Protein B to activate pathway X.\"] * 5 + \\\n",
    "               [\"Protein C binds to Protein D and inhibits pathway Y.\"] * 5\n",
    "test_labels = [0]*5 + [1]*5\n",
    "\n",
    "quantum_evaluation(classifier, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python code is a conceptual example of how quantum computing can be used for natural language processing (NLP) tasks, specifically for text classification. It uses the Qiskit library, an open-source quantum computing software development framework.\n",
    "\n",
    "- `quantum_text_classification` function: Classifies a given document using a quantum support vector machine (QSVM) and returns the test accuracy.\n",
    "\n",
    "- `quantum_feature_extraction` function: Extracts features from the text by encoding it as a quantum state using a quantum circuit, measuring the quantum state, and extracting features from the measurement outcomes.\n",
    "\n",
    "- `quantum_model_training` function: Trains a quantum machine learning model by encoding the labels as quantum states using a quantum circuit, measuring the quantum state, and extracting parameters from the measurement outcomes.\n",
    "\n",
    "- `quantum_evaluation` function: Evaluates the quantum model by encoding the test features as quantum states, evaluating the quantum model, and calculating the accuracy of the predictions.\n",
    "\n",
    "The code also includes a test with random data. It extracts features from a corpus of documents, generates random labels, trains a quantum classifier on the features and labels, and evaluates the classifier.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
