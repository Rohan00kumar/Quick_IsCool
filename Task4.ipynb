{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Healthcare Image Classification\n",
    "\n",
    "A healthcare company wants to develop a model to classify X-ray images into different categories of lung diseases. They have a limited dataset of labeled X-ray images for training. To improve the model's performance, they decide to use transfer learning with a pre-trained model like VGG16.\n",
    "\n",
    "### Task 1: Transfer Learning with VGG16\n",
    "\n",
    "- Implement transfer learning with VGG16 to train a model on the given dataset of X-ray images.\n",
    "- Evaluate the model's performance on a separate test set.\n",
    "- Calculate relevant metrics such as accuracy, precision, recall, and F1 score.\n",
    "\n",
    "### Task 2: Quantum Hyperparameter Optimization\n",
    "\n",
    "- Design a quantum circuit that can be used to optimize the hyperparameters of the neural network model for the X-ray image classification task.\n",
    "- Compare the efficiency of the classical and quantum approaches in terms of hyperparameter optimization time and model performance improvement.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.3.0\n",
      "Numpy version: 1.23.5\n",
      "Pytorch version: 2.0.1+cpu\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: 865972f7a791bf7b42efbcd87c8402bd865b329e\n",
      "MONAI __file__: c:\\Users\\<username>\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\monai\\__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "ITK version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "scikit-image version: 0.21.0\n",
      "scipy version: 1.10.1\n",
      "Pillow version: 9.4.0\n",
      "Tensorboard version: 2.12.3\n",
      "gdown version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "TorchVision version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "tqdm version: 4.65.0\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.9.5\n",
      "pandas version: 2.0.2\n",
      "einops version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "clearml version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.data import decollate_batch, DataLoader\n",
    "from monai.metrics import ROCAUCMetric\n",
    "from monai.networks.nets import DenseNet121\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    EnsureChannelFirst,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    LoadImage,\n",
    "    RandFlip,\n",
    "    RandRotate,\n",
    "    RandZoom,\n",
    "    ScaleIntensity,\n",
    ")\n",
    "from monai.utils import set_determinism\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all imported\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pydicom\n",
    "import pickle\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Timing utility\n",
    "from timeit import default_timer as timer\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "import seaborn as sn\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "\n",
    "print(\"all imported\")\n",
    "\n",
    "set_determinism(seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aortic enlargement', 'Atelectasis', 'Calcification', 'Cardiomegaly', 'Consolidation', 'ILD', 'Infiltration', 'Lung Opacity', 'Nodule/Mass', 'Other lesion', 'Pleural effusion', 'Pleural thickening', 'Pneumothorax', 'Pulmonary fibrosis']\n",
      "['Aortic enlargement', 'Atelectasis', 'Calcification', 'Cardiomegaly', 'Consolidation', 'ILD', 'Infiltration', 'Lung Opacity', 'Nodule/Mass', 'Other lesion', 'Pleural effusion', 'Pleural thickening', 'Pneumothorax', 'Pulmonary fibrosis', 'image_id']\n"
     ]
    }
   ],
   "source": [
    "diseases = ['Aortic enlargement', 'Atelectasis', 'Calcification', 'Cardiomegaly',\n",
    " 'Consolidation', 'ILD', 'Infiltration', 'Lung Opacity', 'Nodule/Mass',\n",
    " 'Other lesion', 'Pleural effusion', 'Pleural thickening', 'Pneumothorax',\n",
    " 'Pulmonary fibrosis']\n",
    "\n",
    "# decided on the basis of frequency of occurence of individual diseases in images.\n",
    "\n",
    "# Drop columns not in the list\n",
    "columns_to_keep = diseases.copy()\n",
    "columns_to_keep.append('image_id')\n",
    "\n",
    "print(diseases)\n",
    "print(columns_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import monai\n",
    "from monai.transforms import Compose, LoadImage, AddChannel, ScaleIntensity, RandRotate, RandFlip, ToTensor\n",
    "from monai.networks.nets import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define transforms\n",
    "train_transforms = Compose([\n",
    "    LoadImage(image_only=True),\n",
    "    AddChannel(),\n",
    "    ScaleIntensity(),\n",
    "    RandRotate(range_x=15, prob=0.5),\n",
    "    RandFlip(spatial_axis=0, prob=0.5),\n",
    "    RandFlip(spatial_axis=1, prob=0.5),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "test_transforms = Compose([\n",
    "    LoadImage(image_only=True),\n",
    "    AddChannel(),\n",
    "    ScaleIntensity(),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "train_dataset = monai.data.ImageDataset(\n",
    "    image_files=train_files,\n",
    "    labels=train_labels,\n",
    "    transform=train_transforms\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_dataset = monai.data.ImageDataset(\n",
    "    image_files=test_files,\n",
    "    labels=test_labels,\n",
    "    transform=test_transforms\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1)\n",
    "\n",
    "# Load pre-trained VGG16 model\n",
    "vgg16 = VGG16(spatial_dims=2, in_channels=1, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze layers except the final classifier layers\n",
    "for param in vgg16.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Define new classifier\n",
    "num_ftrs = vgg16.classifier[6].in_features\n",
    "vgg16.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(vgg16.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    vgg16.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data['image'], data['label']\n",
    "        optimizer.zero_grad()\n",
    "        outputs = vgg16(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "# Evaluate the model\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    vgg16.eval()\n",
    "    for data in test_loader:\n",
    "        images, labels = data['image'], data['label']\n",
    "        outputs = vgg16(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy: {100 * correct / total}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import monai\n",
    "from monai.transforms import Compose, LoadImage, AddChannel, ScaleIntensity, RandRotate, RandFlip, ToTensor\n",
    "from monai.networks.nets import VGG16\n",
    "\n",
    "# Define transforms\n",
    "train_transforms = Compose([\n",
    "    LoadImage(image_only=True),\n",
    "    AddChannel(),\n",
    "    ScaleIntensity(),\n",
    "    RandRotate(range_x=15, prob=0.5),\n",
    "    RandFlip(spatial_axis=0, prob=0.5),\n",
    "    RandFlip(spatial_axis=1, prob=0.5),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "test_transforms = Compose([\n",
    "    LoadImage(image_only=True),\n",
    "    AddChannel(),\n",
    "    ScaleIntensity(),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "train_dataset = monai.data.ImageDataset(\n",
    "    image_files=train_files,\n",
    "    labels=train_labels,\n",
    "    transform=train_transforms\n",
    ")\n",
    "\n",
    "test_dataset = monai.data.ImageDataset(\n",
    "    image_files=test_files,\n",
    "    labels=test_labels,\n",
    "    transform=test_transforms\n",
    ")\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1)\n",
    "\n",
    "# Load pre-trained VGG16 model\n",
    "vgg16 = VGG16(spatial_dims=2, in_channels=1, num_classes=num_classes)\n",
    "\n",
    "# Freeze layers except the final classifier layers\n",
    "for param in vgg16.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Define new classifier\n",
    "num_ftrs = vgg16.classifier[6].in_features\n",
    "vgg16.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(vgg16.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    vgg16.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data['image'], data['label']\n",
    "        optimizer.zero_grad()\n",
    "        outputs = vgg16(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "# Evaluate the model\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    vgg16.eval()\n",
    "    for data in test_loader:\n",
    "        images, labels = data['image'], data['label']\n",
    "        outputs = vgg16(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy: {100 * correct / total}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python code uses the PyTorch and MONAI libraries to train a convolutional neural network (CNN) for image classification. The specific CNN used is VGG16, a popular model known for its simplicity and high performance on the ImageNet dataset.\n",
    "\n",
    "The code performs the following steps:\n",
    "\n",
    "1. Import the necessary libraries and modules.\n",
    "2. Define transformations for the training and testing datasets, including loading the image, adding a channel dimension, scaling the intensity, and converting to a PyTorch tensor.\n",
    "3. Load the training and testing datasets using MONAI's `ImageDataset` class and apply the defined transformations.\n",
    "4. Create data loaders for the training and testing datasets.\n",
    "5. Load the pre-trained VGG16 model using MONAI's `VGG16` class.\n",
    "6. Modify the model by freezing all layers except the final classifier layer and replacing the final classifier layer with a new linear layer.\n",
    "7. Define the loss function as cross-entropy and the optimizer as Adam with a learning rate of 0.001.\n",
    "8. Train the model for a specified number of epochs, updating the parameters to minimize the loss on the training data.\n",
    "9. Print the loss for each epoch.\n",
    "10. Evaluate the trained model on the testing data and calculate the accuracy.\n",
    "\n",
    "This code provides a framework for training and evaluating a CNN model using VGG16 for image classification tasks.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
